# 04b_video_to_3d_visualization.py
# è§†é¢‘åˆ°3Då…³é”®ç‚¹çš„å¯è§†åŒ–å·¥å…· - åŒæ—¶æ˜¾ç¤º2Dè§†é¢‘å’Œ3DåŠ¨ç”»

import os
import cv2
import numpy as np
import torch
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.animation as animation
from matplotlib.widgets import Slider, Button
from tqdm import tqdm
from common.ap10k_detector import AP10KAnimalPoseDetector
from common.keypoint_mapper import KeypointMapper
from common.transformer_model import UltraLightAnimalPoseTransformer

# éª¨æ¶åˆ†ç»„å®šä¹‰ï¼ˆä¸è®­ç»ƒæ•°æ®ä¸€è‡´ï¼‰
SKELETON_GROUPS = {
    'trunk': {
        'edges': [(0, 4), (4, 3), (3, 1), (3, 2)],
        'color': 'black', 'label': 'Head & Neck'
    },
    'front_left': {
        'edges': [(4, 5), (5, 6), (6, 7)],
        'color': 'red', 'label': 'Front Left'
    },
    'front_right': {
        'edges': [(4, 8), (8, 9), (9, 10)],
        'color': 'orange', 'label': 'Front Right'
    },
    'back_left': {
        'edges': [(0, 11), (11, 12), (12, 13)],
        'color': 'blue', 'label': 'Back Left'
    },
    'back_right': {
        'edges': [(0, 14), (14, 15), (15, 16)],
        'color': 'cyan', 'label': 'Back Right'
    }
}

# 2Då¯è§†åŒ–é¢œè‰²å®šä¹‰
SKELETON_COLORS_2D = {
    'trunk': (0, 0, 0),        # é»‘è‰²
    'front_left': (0, 0, 255),  # çº¢è‰²
    'front_right': (0, 165, 255),  # æ©™è‰²
    'back_left': (255, 0, 0),   # è“è‰²
    'back_right': (255, 255, 0) # é’è‰²
}


class VideoTo3DVisualizer:
    def __init__(self, model_checkpoint, onnx_model_path):
        """åˆå§‹åŒ–å¯è§†åŒ–å™¨"""
        print("ğŸ¯ åˆå§‹åŒ–è§†é¢‘åˆ°3Då¯è§†åŒ–å™¨...")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.detector = AP10KAnimalPoseDetector(onnx_model_path)
        self.mapper = KeypointMapper()
        
        # åŠ è½½3Dæ¨¡å‹
        self.model_3d = self.load_3d_model(model_checkpoint)
        
        # è§†é¢‘ç›¸å…³å˜é‡
        self.video_cap = None
        self.video_frames = []
        self.video_info = {}
        
        # å…³é”®ç‚¹æ•°æ®
        self.keypoints_2d_sequence = []
        self.keypoints_3d_sequence = []
        
        print("âœ… å¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_3d_model(self, checkpoint_path):
        """åŠ è½½è®­ç»ƒå¥½çš„3Då§¿æ€ä¼°è®¡æ¨¡å‹"""
        print(f"ğŸ“¥ åŠ è½½3Dæ¨¡å‹: {checkpoint_path}")
        
        if not os.path.exists(checkpoint_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return None
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å‚æ•°ï¼‰
        model = UltraLightAnimalPoseTransformer(
            num_joints=17, 
            in_dim=2, 
            embed_dim=96,
            depth=2, 
            num_heads=4, 
            seq_len=16, 
            dropout=0.1
        )
        
        # åŠ è½½æƒé‡
        try:
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            elif 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            else:
                # ç›´æ¥åŠ è½½æ•´ä¸ªæ£€æŸ¥ç‚¹
                model.load_state_dict(checkpoint)
            
            print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
            
            # è®¡ç®—å‚æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {total_params:,}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
        
        model.eval()
        
        if torch.cuda.is_available():
            model = model.cuda()
            print("âœ… æ¨¡å‹å·²ç§»åŠ¨åˆ°GPU")
        else:
            print("â„¹ï¸ ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
        
        return model
    
    def extract_video_frames(self, video_path, max_frames=100):
        """æå–è§†é¢‘å¸§å¹¶æ£€æµ‹2Då…³é”®ç‚¹"""
        print(f"ğŸ¥ å¤„ç†è§†é¢‘: {video_path}")
        
        # æ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # é™åˆ¶å¤„ç†å¸§æ•°
        if max_frames is not None:
            total_frames = min(total_frames, max_frames)
        
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {total_frames}å¸§, {fps:.1f}FPS, åˆ†è¾¨ç‡: {frame_width}x{frame_height}")
        
        self.video_info = {
            'fps': fps,
            'total_frames': total_frames,
            'resolution': (frame_width, frame_height),
            'video_path': video_path
        }
        
        # æå–å¸§å’Œå…³é”®ç‚¹
        self.video_frames = []
        self.keypoints_2d_sequence = []
        valid_frames = 0
        
        pbar = tqdm(total=total_frames, desc="æå–è§†é¢‘å¸§å’Œå…³é”®ç‚¹")
        
        for frame_idx in range(total_frames):
            ret, frame = cap.read()
            if not ret:
                break
            
            # ä¿å­˜åŸå§‹å¸§
            self.video_frames.append(frame.copy())
            
            # ä¿å­˜ä¸´æ—¶å›¾åƒç”¨äºæ£€æµ‹
            temp_img_path = f"temp_frame_{frame_idx:06d}.jpg"
            cv2.imwrite(temp_img_path, frame)
            
            try:
                # æ£€æµ‹2Då…³é”®ç‚¹
                result = self.detector.predict(temp_img_path)
                keypoints_ap10k = result['keypoints']
                
                # è¿‡æ»¤ä½ç½®ä¿¡åº¦å…³é”®ç‚¹
                valid_keypoints = np.sum(keypoints_ap10k[:, 2] > 0.3)
                
                if valid_keypoints >= 8:  # è‡³å°‘8ä¸ªæœ‰æ•ˆå…³é”®ç‚¹
                    # æ˜ å°„åˆ°è®­ç»ƒæ ¼å¼
                    keypoints_training = self.mapper.map_ap10k_to_training(keypoints_ap10k)
                    keypoints_2d = keypoints_training[:, :2]  # åªä¿ç•™åæ ‡
                    
                    self.keypoints_2d_sequence.append(keypoints_2d)
                    valid_frames += 1
                else:
                    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¶³å¤Ÿçš„å…³é”®ç‚¹ï¼Œæ·»åŠ ç©ºæ•°æ®
                    self.keypoints_2d_sequence.append(np.full((17, 2), np.nan))
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_img_path)
                
            except Exception as e:
                if frame_idx % 50 == 0:
                    print(f"âš ï¸ å¸§ {frame_idx} å¤„ç†å¤±è´¥: {e}")
                # æ·»åŠ ç©ºæ•°æ®
                self.keypoints_2d_sequence.append(np.full((17, 2), np.nan))
                if os.path.exists(temp_img_path):
                    os.remove(temp_img_path)
            
            pbar.update(1)
        
        pbar.close()
        cap.release()
        
        print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ: {valid_frames}/{total_frames} æœ‰æ•ˆå¸§")
        
        return valid_frames
    
    def convert_2d_to_3d(self):
        """å°†2Då…³é”®ç‚¹åºåˆ—è½¬æ¢ä¸º3Då…³é”®ç‚¹"""
        print("ğŸ”„ å¼€å§‹2Dåˆ°3Dè½¬æ¢...")
        
        if len(self.keypoints_2d_sequence) == 0:
            print("âŒ æ²¡æœ‰2Då…³é”®ç‚¹æ•°æ®")
            return False
        
        # è¿‡æ»¤æ— æ•ˆå¸§
        valid_keypoints = []
        valid_indices = []
        
        for i, kps in enumerate(self.keypoints_2d_sequence):
            if not np.any(np.isnan(kps)):
                valid_keypoints.append(kps)
                valid_indices.append(i)
        
        if len(valid_keypoints) < 16:
            print(f"âŒ æœ‰æ•ˆå¸§æ•° ({len(valid_keypoints)}) ä¸è¶³ï¼Œéœ€è¦è‡³å°‘16å¸§")
            return False
        
        print(f"ğŸ“Š ä½¿ç”¨ {len(valid_keypoints)} ä¸ªæœ‰æ•ˆå¸§è¿›è¡Œ3Dè½¬æ¢")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        keypoints_2d_array = np.array(valid_keypoints)
        
        # å½’ä¸€åŒ–å…³é”®ç‚¹ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        keypoints_2d_normalized = self.normalize_keypoints(keypoints_2d_array)
        
        # åˆ†å—å¤„ç†ï¼ˆé€‚åº”æ¨¡å‹è¾“å…¥é•¿åº¦ï¼‰
        self.keypoints_3d_sequence = []
        seq_len = 16  # æ¨¡å‹è¾“å…¥åºåˆ—é•¿åº¦
        
        for i in range(0, len(keypoints_2d_normalized) - seq_len + 1, seq_len):
            chunk = keypoints_2d_normalized[i:i+seq_len]
            
            with torch.no_grad():
                # å‡†å¤‡è¾“å…¥
                inputs_2d = torch.from_numpy(chunk.astype('float32')).unsqueeze(0)
                
                if torch.cuda.is_available():
                    inputs_2d = inputs_2d.cuda()
                
                # æ¨¡å‹æ¨ç†
                predicted_3d = self.model_3d(inputs_2d)
                chunk_3d = predicted_3d.squeeze(0).cpu().numpy()
                
                # åå½’ä¸€åŒ–åˆ°åŸå§‹å°ºåº¦
                chunk_3d_denorm = self.denormalize_3d(chunk_3d, keypoints_2d_array[i:i+seq_len])
                
                # æ˜ å°„å›åŸå§‹å¸§ç´¢å¼•
                for j in range(len(chunk_3d_denorm)):
                    frame_3d = np.full((17, 3), np.nan)
                    frame_3d[:] = chunk_3d_denorm[j]
                    self.keypoints_3d_sequence.append(frame_3d)
        
        print(f"âœ… 3Dè½¬æ¢å®Œæˆ: {len(self.keypoints_3d_sequence)} å¸§3Då…³é”®ç‚¹")
        return True
    
    def normalize_keypoints(self, keypoints_2d):
        """å½’ä¸€åŒ–2Då…³é”®ç‚¹åˆ° [-1, 1] èŒƒå›´"""
        normalized = []
        
        for frame_kps in keypoints_2d:
            # æ‰¾åˆ°è¾¹ç•Œ
            min_val = frame_kps.min(axis=0)
            max_val = frame_kps.max(axis=0)
            
            # è®¡ç®—ä¸­å¿ƒå’Œå°ºåº¦
            center = (min_val + max_val) / 2
            scale = np.max(max_val - min_val)
            
            if scale == 0:
                scale = 1.0
            
            # å½’ä¸€åŒ–
            normalized_frame = (frame_kps - center) / (scale / 2)
            normalized.append(normalized_frame)
        
        return np.array(normalized)
    
    def denormalize_3d(self, keypoints_3d, original_2d):
        """å°†3Då…³é”®ç‚¹åå½’ä¸€åŒ–åˆ°åˆç†å°ºåº¦"""
        denormalized = []
        
        for i, frame_3d in enumerate(keypoints_3d):
            # ä½¿ç”¨åŸå§‹2Dæ•°æ®çš„å°ºåº¦ä¿¡æ¯
            frame_2d = original_2d[i]
            
            # è®¡ç®—2Dæ•°æ®çš„å°ºåº¦
            min_2d = frame_2d.min(axis=0)
            max_2d = frame_2d.max(axis=0)
            scale_2d = np.max(max_2d - min_2d)
            
            if scale_2d == 0:
                scale_2d = 100.0  # é»˜è®¤å°ºåº¦
            
            # å°†3Dæ•°æ®ç¼©æ”¾åˆ°åˆç†èŒƒå›´
            scale_3d = scale_2d * 0.5  # 3Då°ºåº¦çº¦ä¸º2Dçš„ä¸€åŠ
            frame_3d_scaled = frame_3d * scale_3d
            

            # frame_3d_scaled[:, 0] = -frame_3d_scaled[:, 0]  # åè½¬Xè½´
            # frame_3d_scaled[:, 1] = -frame_3d_scaled[:, 1]
            frame_3d_scaled[:, 2] = -frame_3d_scaled[:, 2]  # åè½¬Zè½´
            
            denormalized.append(frame_3d_scaled)
        
        return np.array(denormalized)
    
    def draw_2d_skeleton(self, frame, keypoints_2d, confidence_threshold=0.3):
        """åœ¨è§†é¢‘å¸§ä¸Šç»˜åˆ¶2Déª¨æ¶"""
        if np.any(np.isnan(keypoints_2d)):
            return frame
        
        frame_with_skeleton = frame.copy()
        
        # ç»˜åˆ¶å…³èŠ‚ç‚¹
        for i, (x, y) in enumerate(keypoints_2d):
            if not np.isnan(x) and not np.isnan(y):
                center = (int(x), int(y))
                cv2.circle(frame_with_skeleton, center, 4, (0, 255, 255), -1)  # é»„è‰²ç‚¹
                cv2.putText(frame_with_skeleton, str(i), (center[0] + 5, center[1]),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        # ç»˜åˆ¶éª¨æ¶è¿çº¿
        for group_name, group_info in SKELETON_GROUPS.items():
            color = SKELETON_COLORS_2D[group_name]
            
            for edge in group_info['edges']:
                start_joint, end_joint = edge
                
                if (start_joint < len(keypoints_2d) and end_joint < len(keypoints_2d) and
                    not np.any(np.isnan(keypoints_2d[start_joint])) and 
                    not np.any(np.isnan(keypoints_2d[end_joint]))):
                    
                    start_point = (int(keypoints_2d[start_joint][0]), int(keypoints_2d[start_joint][1]))
                    end_point = (int(keypoints_2d[end_joint][0]), int(keypoints_2d[end_joint][1]))
                    
                    cv2.line(frame_with_skeleton, start_point, end_point, color, 2)
        
        return frame_with_skeleton
    
    def create_3d_visualization(self, sequence_3d, title="3D Animal Pose"):
        """åˆ›å»º3Då…³é”®ç‚¹åŠ¨ç”»å¯è§†åŒ–"""
        print("ğŸ¨ åˆ›å»º3Då¯è§†åŒ–...")
        
        # ä½¿ç”¨æ›´ç¨³å®šçš„åç«¯
        import matplotlib
        matplotlib.use('TkAgg')
        
        fig = plt.figure(figsize=(16, 8))
        
        # åˆ›å»º3Då­å›¾
        ax_3d = fig.add_subplot(121, projection='3d')
        
        # è®¡ç®—åˆé€‚çš„åæ ‡è½´èŒƒå›´
        valid_positions = []
        for frame in sequence_3d:
            if not np.any(np.isnan(frame)):
                valid_positions.extend(frame)
        
        if len(valid_positions) == 0:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„3Dæ•°æ®ç‚¹")
            return
        
        valid_positions = np.array(valid_positions)
        
        max_range = np.array([
            valid_positions[:, 0].max() - valid_positions[:, 0].min(),
            valid_positions[:, 1].max() - valid_positions[:, 1].min(),
            valid_positions[:, 2].max() - valid_positions[:, 2].min()
        ]).max() / 2.0
        
        if max_range == 0:
            max_range = 1.0
        
        mid_x = (valid_positions[:, 0].max() + valid_positions[:, 0].min()) * 0.5
        mid_y = (valid_positions[:, 1].max() + valid_positions[:, 1].min()) * 0.5
        mid_z = (valid_positions[:, 2].max() + valid_positions[:, 2].min()) * 0.5
        
        ax_3d.set_xlim(mid_x - max_range, mid_x + max_range)
        ax_3d.set_ylim(mid_y - max_range, mid_y + max_range)
        ax_3d.set_zlim(mid_z - max_range, mid_z + max_range)
        
        # è®¾ç½®åæ ‡è½´æ ‡ç­¾
        ax_3d.set_xlabel('X', fontsize=10)
        ax_3d.set_ylabel('Y', fontsize=10)
        ax_3d.set_zlabel('Z', fontsize=10)
        
        # è®¾ç½®å›ºå®šè§†è§’
        ax_3d.view_init(elev=20., azim=45)
        
        # å­˜å‚¨ç»˜å›¾å¯¹è±¡
        scatter_plot = None
        line_plots = {}
        
        def update_3d_frame(frame_idx):
            """æ›´æ–°3Då¸§æ˜¾ç¤º"""
            nonlocal scatter_plot, line_plots
            
            # æ¸…é™¤ä¹‹å‰çš„ç»˜å›¾
            if scatter_plot is not None:
                scatter_plot.remove()
            for line_plot in line_plots.values():
                line_plot.remove()
            line_plots.clear()
            
            # è·å–å½“å‰å¸§æ•°æ®
            if frame_idx >= len(sequence_3d):
                return
            
            frame_data = sequence_3d[frame_idx]
            
            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if np.any(np.isnan(frame_data)):
                return
            
            # ç»˜åˆ¶å…³èŠ‚ç‚¹
            scatter_plot = ax_3d.scatter(
                frame_data[:, 0], frame_data[:, 1], frame_data[:, 2], 
                color='darkred', s=30, alpha=0.8, label='Joints'
            )
            
            # ç»˜åˆ¶éª¨éª¼è¿æ¥
            labels_added = set()
            for group_name, group_info in SKELETON_GROUPS.items():
                for edge in group_info['edges']:
                    start_joint, end_joint = edge
                    if (start_joint < len(frame_data) and end_joint < len(frame_data) and
                        not np.any(np.isnan(frame_data[start_joint])) and 
                        not np.any(np.isnan(frame_data[end_joint]))):
                        
                        start_pos = frame_data[start_joint]
                        end_pos = frame_data[end_joint]
                        
                        line_plot, = ax_3d.plot(
                            [start_pos[0], end_pos[0]], 
                            [start_pos[1], end_pos[1]], 
                            [start_pos[2], end_pos[2]], 
                            color=group_info['color'], 
                            linewidth=2, 
                            label=group_info['label'] if group_name not in labels_added else ""
                        )
                        line_plots[f"{group_name}_{edge}"] = line_plot
                        labels_added.add(group_name)
            
            # è®¾ç½®æ ‡é¢˜
            ax_3d.set_title(f'{title}\nå¸§ {frame_idx+1}/{len(sequence_3d)}', 
                           fontsize=12, fontweight='bold', pad=10)
        
        # åˆå§‹æ˜¾ç¤º
        update_3d_frame(0)
        
        # æ·»åŠ å›¾ä¾‹
        handles, labels = ax_3d.get_legend_handles_labels()
        by_label = dict(zip(labels, handles))
        if by_label:
            ax_3d.legend(by_label.values(), by_label.keys(), loc='upper left', fontsize=8)
        
        # åˆ›å»ºåŠ¨ç”»
        ani_3d = animation.FuncAnimation(
            fig, update_3d_frame, frames=min(len(sequence_3d), 100), 
            interval=100, repeat=True, blit=False
        )
        
        return fig, ax_3d, ani_3d
    
    def visualize_combined(self, video_path, max_frames=100):
        """ç»„åˆå¯è§†åŒ–ï¼šå·¦ä¾§æ˜¾ç¤º2Dè§†é¢‘ï¼Œå³ä¾§æ˜¾ç¤º3DåŠ¨ç”»"""
        print("ğŸ¬ å¼€å§‹ç»„åˆå¯è§†åŒ–...")
        
        # 1. æå–è§†é¢‘å¸§å’Œ2Då…³é”®ç‚¹
        valid_frames = self.extract_video_frames(video_path, max_frames)
        if valid_frames < 16:
            print(f"âŒ æœ‰æ•ˆå¸§æ•°ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œ3Dè½¬æ¢")
            return
        
        # 2. è½¬æ¢ä¸º3Då…³é”®ç‚¹
        if not self.convert_2d_to_3d():
            print("âŒ 3Dè½¬æ¢å¤±è´¥")
            return
        
        # 3. åˆ›å»ºå¯è§†åŒ–ç•Œé¢
        import matplotlib
        matplotlib.use('TkAgg')
        
        fig = plt.figure(figsize=(20, 8))
        
        # å·¦ä¾§ï¼š2Dè§†é¢‘æ˜¾ç¤º
        ax_2d = fig.add_subplot(121)
        ax_2d.set_title("2Dè§†é¢‘ä¸å…³é”®ç‚¹æ£€æµ‹", fontsize=14, fontweight='bold')
        ax_2d.axis('off')
        
        # å³ä¾§ï¼š3DåŠ¨ç”»æ˜¾ç¤º
        ax_3d = fig.add_subplot(122, projection='3d')
        ax_3d.set_title("3Då§¿æ€ä¼°è®¡", fontsize=14, fontweight='bold')
        
        # è®¡ç®—3Dåæ ‡è½´èŒƒå›´
        valid_3d_positions = []
        for frame in self.keypoints_3d_sequence:
            if not np.any(np.isnan(frame)):
                valid_3d_positions.extend(frame)
        
        if len(valid_3d_positions) == 0:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„3Dæ•°æ®")
            return
        
        valid_3d_positions = np.array(valid_3d_positions)
        max_range = np.array([
            valid_3d_positions[:, 0].max() - valid_3d_positions[:, 0].min(),
            valid_3d_positions[:, 1].max() - valid_3d_positions[:, 1].min(),
            valid_3d_positions[:, 2].max() - valid_3d_positions[:, 2].min()
        ]).max() / 2.0
        
        if max_range == 0:
            max_range = 1.0
        
        mid_x = (valid_3d_positions[:, 0].max() + valid_3d_positions[:, 0].min()) * 0.5
        mid_y = (valid_3d_positions[:, 1].max() + valid_3d_positions[:, 1].min()) * 0.5
        mid_z = (valid_3d_positions[:, 2].max() + valid_3d_positions[:, 2].min()) * 0.5
        
        ax_3d.set_xlim(mid_x - max_range, mid_x + max_range)
        ax_3d.set_ylim(mid_y - max_range, mid_y + max_range)
        ax_3d.set_zlim(mid_z - max_range, mid_z + max_range)
        
        ax_3d.set_xlabel('X')
        ax_3d.set_ylabel('Y')
        ax_3d.set_zlabel('Z')
        ax_3d.view_init(elev=20., azim=45)
        
        # å­˜å‚¨ç»˜å›¾å¯¹è±¡
        img_display = None
        scatter_3d = None
        line_plots_3d = {}
        
        def update_combined_frame(frame_idx):
            """æ›´æ–°ç»„åˆå¸§æ˜¾ç¤º"""
            nonlocal img_display, scatter_3d, line_plots_3d
            
            # æ›´æ–°2Dæ˜¾ç¤º
            if frame_idx < len(self.video_frames):
                frame_2d = self.video_frames[frame_idx]
                
                # ç»˜åˆ¶2Déª¨æ¶
                if frame_idx < len(self.keypoints_2d_sequence):
                    frame_with_skeleton = self.draw_2d_skeleton(frame_2d, self.keypoints_2d_sequence[frame_idx])
                else:
                    frame_with_skeleton = frame_2d
                
                # è½¬æ¢ä¸ºRGBæ ¼å¼
                frame_rgb = cv2.cvtColor(frame_with_skeleton, cv2.COLOR_BGR2RGB)
                
                if img_display is None:
                    img_display = ax_2d.imshow(frame_rgb)
                else:
                    img_display.set_data(frame_rgb)
                
                ax_2d.set_title(f"2Dè§†é¢‘ (å¸§ {frame_idx+1}/{len(self.video_frames)})", 
                               fontsize=12, fontweight='bold')
            
            # æ›´æ–°3Dæ˜¾ç¤º
            if frame_idx < len(self.keypoints_3d_sequence):
                frame_3d = self.keypoints_3d_sequence[frame_idx]
                
                # æ¸…é™¤ä¹‹å‰çš„3Dç»˜å›¾
                if scatter_3d is not None:
                    scatter_3d.remove()
                for line_plot in line_plots_3d.values():
                    line_plot.remove()
                line_plots_3d.clear()
                
                # æ£€æŸ¥3Dæ•°æ®æœ‰æ•ˆæ€§
                if not np.any(np.isnan(frame_3d)):
                    # ç»˜åˆ¶3Då…³èŠ‚ç‚¹
                    scatter_3d = ax_3d.scatter(
                        frame_3d[:, 0], frame_3d[:, 1], frame_3d[:, 2], 
                        color='darkred', s=30, alpha=0.8, label='Joints'
                    )
                    
                    # ç»˜åˆ¶3Déª¨éª¼è¿æ¥
                    labels_added = set()
                    for group_name, group_info in SKELETON_GROUPS.items():
                        for edge in group_info['edges']:
                            start_joint, end_joint = edge
                            if (start_joint < len(frame_3d) and end_joint < len(frame_3d) and
                                not np.any(np.isnan(frame_3d[start_joint])) and 
                                not np.any(np.isnan(frame_3d[end_joint]))):
                                
                                start_pos = frame_3d[start_joint]
                                end_pos = frame_3d[end_joint]
                                
                                line_plot, = ax_3d.plot(
                                    [start_pos[0], end_pos[0]], 
                                    [start_pos[1], end_pos[1]], 
                                    [start_pos[2], end_pos[2]], 
                                    color=group_info['color'], 
                                    linewidth=2, 
                                    label=group_info['label'] if group_name not in labels_added else ""
                                )
                                line_plots_3d[f"{group_name}_{edge}"] = line_plot
                                labels_added.add(group_name)
                
                ax_3d.set_title(f"3Då§¿æ€ä¼°è®¡ (å¸§ {frame_idx+1}/{len(self.keypoints_3d_sequence)})", 
                               fontsize=12, fontweight='bold')
        
        # åˆå§‹æ˜¾ç¤º
        update_combined_frame(0)
        
        # æ·»åŠ 3Då›¾ä¾‹
        handles, labels = ax_3d.get_legend_handles_labels()
        by_label = dict(zip(labels, handles))
        if by_label:
            ax_3d.legend(by_label.values(), by_label.keys(), loc='upper left', fontsize=8)
        
        # æ·»åŠ æ§åˆ¶é¢æ¿
        plt.subplots_adjust(bottom=0.15)
        
        # æ»‘å—æ§åˆ¶
        ax_slider = plt.axes([0.2, 0.05, 0.6, 0.03], facecolor='lightgoldenrodyellow')
        total_frames = max(len(self.video_frames), len(self.keypoints_3d_sequence))
        frame_slider = Slider(ax_slider, 'å¸§', 0, total_frames-1, valinit=0, valstep=1)
        
        def update_slider(val):
            frame_idx = int(frame_slider.val)
            update_combined_frame(frame_idx)
            fig.canvas.draw_idle()
        
        frame_slider.on_changed(update_slider)
        
        # æ’­æ”¾/æš‚åœæŒ‰é’®
        ax_play = plt.axes([0.15, 0.01, 0.1, 0.04])
        play_button = Button(ax_play, 'â–¶ æ’­æ”¾/æš‚åœ', color='lightblue', hovercolor='lightcyan')
        
        playing = [True]
        ani_combined = animation.FuncAnimation(
            fig, update_combined_frame, frames=min(total_frames, 100), 
            interval=100, repeat=True, blit=False
        )
        
        def toggle_animation(event):
            if playing[0]:
                ani_combined.event_source.stop()
                play_button.label.set_text('â–¶ æ’­æ”¾')
            else:
                ani_combined.event_source.start()
                play_button.label.set_text('â¸ æš‚åœ')
            playing[0] = not playing[0]
        
        play_button.on_clicked(toggle_animation)
        
        # é‡ç½®æŒ‰é’®
        ax_reset = plt.axes([0.27, 0.01, 0.1, 0.04])
        reset_button = Button(ax_reset, 'â†º é‡ç½®', color='lightgreen', hovercolor='lightcyan')
        
        def reset_animation(event):
            frame_slider.set_val(0)
            update_combined_frame(0)
            if not playing[0]:
                ani_combined.event_source.start()
                play_button.label.set_text('â¸ æš‚åœ')
                playing[0] = True
            fig.canvas.draw_idle()
        
        reset_button.on_clicked(reset_animation)
        
        print("ğŸ‰ ç»„åˆå¯è§†åŒ–å·²åˆ›å»º!")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨æ»‘å—æ§åˆ¶å¸§ï¼ŒæŒ‰é’®æ§åˆ¶æ’­æ”¾ï¼Œé¼ æ ‡æ‹–åŠ¨æ—‹è½¬3Dè§†è§’")
        
        plt.tight_layout()
        plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ¯ è§†é¢‘åˆ°3Då…³é”®ç‚¹å¯è§†åŒ–å·¥å…·")
    print("=" * 70)
    
    # é…ç½®è·¯å¾„
    MODEL_CHECKPOINT = "checkpoint/best_model.pt"
    ONNX_MODEL_PATH = "model/ap10k/end2end.onnx"
    VIDEO_PATH = "video/test_video_yang.mp4"  # æ›¿æ¢ä¸ºä½ çš„è§†é¢‘è·¯å¾„
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(ONNX_MODEL_PATH):
        print(f"âŒ ONNXæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ONNX_MODEL_PATH}")
        print("ğŸ’¡ è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        return
    
    if not os.path.exists(VIDEO_PATH):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {VIDEO_PATH}")
        print("ğŸ’¡ è¯·æä¾›æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„")
        return
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = VideoTo3DVisualizer(MODEL_CHECKPOINT, ONNX_MODEL_PATH)
    
    if visualizer.model_3d is None:
        print("âŒ 3Dæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # æ‰§è¡Œç»„åˆå¯è§†åŒ–
    try:
        visualizer.visualize_combined(VIDEO_PATH, max_frames=100)
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()