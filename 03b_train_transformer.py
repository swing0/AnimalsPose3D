import os
import sys
import numpy as np
import torch
import torch.optim as optim
from collections import defaultdict
from tqdm import tqdm

# æ·»åŠ è·¯å¾„
sys.path.append('./common')

# å¯¼å…¥æœ¬åœ°æ¨¡å—
try:
    from common.animals_dataset import AnimalsDataset
    from common.loss import mpjpe
    from common.generators import ChunkedGenerator
    from common.arguments import parse_args
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿commonç›®å½•å­˜åœ¨ä¸”åŒ…å«æ‰€éœ€æ¨¡å—")
    sys.exit(1)

# å¯¼å…¥è½»é‡æ¨¡å‹
try:
    from common.transformer_model import UltraLightAnimalPoseTransformer
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ultra_light_transformer")
    print("è¯·ç¡®ä¿ultra_light_transformer.pyåœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)

# ========== é…ç½®å’Œè¾…åŠ©å‡½æ•° ==========

# éª¨æ¶è¿çº¿
SKELETON_EDGES = [
    (0, 4), (4, 3), (3, 1), (3, 2), (4, 5), (5, 6), (6, 7),
    (4, 8), (8, 9), (9, 10), (0, 11), (11, 12), (12, 13), 
    (0, 14), (14, 15), (15, 16)
]

def bone_length_loss(pred, gt):
    """éª¨éª¼é•¿åº¦ä¸€è‡´æ€§æŸå¤±"""
    p1 = pred[:, :, [e[0] for e in SKELETON_EDGES], :]
    p2 = pred[:, :, [e[1] for e in SKELETON_EDGES], :]
    g1 = gt[:, :, [e[0] for e in SKELETON_EDGES], :]
    g2 = gt[:, :, [e[1] for e in SKELETON_EDGES], :]
    
    pred_bones = torch.norm(p1 - p2, dim=-1)
    gt_bones = torch.norm(g1 - g2, dim=-1)
    
    return torch.mean(torch.abs(pred_bones - gt_bones))

def create_balanced_split(all_data_source, train_ratio=0.8, seed=42):
    """å¹³è¡¡æ•°æ®åˆ’åˆ† - ç¡®ä¿æ¯ç§åŠ¨ç‰©éƒ½æœ‰è®­ç»ƒå’ŒéªŒè¯æ ·æœ¬"""
    np.random.seed(seed)
    
    # æŒ‰åŠ¨ç‰©åˆ†ç»„
    animal_groups = defaultdict(list)
    for animal, action in all_data_source:
        animal_groups[animal].append((animal, action))
    
    train_sources, val_sources = [], []
    
    print("ğŸ“Š å¹³è¡¡æ•°æ®åˆ’åˆ†:")
    for animal, sequences in animal_groups.items():
        # éšæœºæ‰“ä¹±
        np.random.shuffle(sequences)
        
        # æŒ‰æ¯”ä¾‹åˆ’åˆ†
        split_idx = int(len(sequences) * train_ratio)
        
        train_sources.extend(sequences[:split_idx])
        val_sources.extend(sequences[split_idx:])
        
        train_count = len(sequences[:split_idx])
        val_count = len(sequences[split_idx:])
        print(f"  {animal}: {train_count}è®­ç»ƒ + {val_count}éªŒè¯")
    
    print(f"æ€»è®¡: {len(train_sources)}è®­ç»ƒ, {len(val_sources)}éªŒè¯")
    return train_sources, val_sources

def truncate_sequence(data, target_length=16):
    """æˆªæ–­æˆ–å¡«å……åºåˆ—åˆ°ç›®æ ‡é•¿åº¦"""
    current_length = len(data)
    
    if current_length >= target_length:
        # ä»ä¸­é—´æˆªå–
        start = (current_length - target_length) // 2
        return data[start:start + target_length]
    else:
        # å¡«å……
        pad_length = target_length - current_length
        # è¾¹ç¼˜å¡«å……æ¨¡å¼
        return np.pad(data, ((0, pad_length), (0, 0), (0, 0)), mode='edge')

def fetch_data_with_truncation(data_source, keypoints_2d, dataset, target_length=16, label=""):
    """è·å–æ•°æ®å¹¶æˆªæ–­åˆ°ç»Ÿä¸€é•¿åº¦"""
    o3, o2 = [], []
    
    print(f"ğŸ“¥ è·å–{label}æ•°æ® (æˆªæ–­åˆ°{target_length}å¸§)...")
    
    for animal, action in tqdm(data_source, desc=f"å¤„ç†{label}", ncols=80):
        if animal in keypoints_2d and action in keypoints_2d[animal]:
            num_views = len(keypoints_2d[animal][action])
            for view_idx in range(num_views):
                # è·å–åŸå§‹æ•°æ®
                seq_2d = keypoints_2d[animal][action][view_idx]
                seq_3d = dataset[animal][action]['positions_3d'][view_idx]
                
                # æˆªæ–­åˆ°ç»Ÿä¸€é•¿åº¦
                seq_2d = truncate_sequence(seq_2d, target_length)
                seq_3d = truncate_sequence(seq_3d, target_length)
                
                o2.append(seq_2d)
                o3.append(seq_3d)
    
    return o3, o2

def check_data_shapes(train_2d, train_3d, val_2d, val_3d):
    """æ£€æŸ¥æ•°æ®å½¢çŠ¶"""
    print("\nğŸ“ æ•°æ®å½¢çŠ¶æ£€æŸ¥:")
    print(f"è®­ç»ƒ2D: {len(train_2d)}åºåˆ—, å½¢çŠ¶: {train_2d[0].shape}")
    print(f"è®­ç»ƒ3D: {len(train_3d)}åºåˆ—, å½¢çŠ¶: {train_3d[0].shape}")
    print(f"éªŒè¯2D: {len(val_2d)}åºåˆ—, å½¢çŠ¶: {val_2d[0].shape}")
    print(f"éªŒè¯3D: {len(val_3d)}åºåˆ—, å½¢çŠ¶: {val_3d[0].shape}")
    
    # æ£€æŸ¥ä¸€è‡´æ€§
    assert train_2d[0].shape == val_2d[0].shape, "è®­ç»ƒå’ŒéªŒè¯2Då½¢çŠ¶ä¸ä¸€è‡´"
    assert train_3d[0].shape == val_3d[0].shape, "è®­ç»ƒå’ŒéªŒè¯3Då½¢çŠ¶ä¸ä¸€è‡´"
    assert train_2d[0].shape[:2] == train_3d[0].shape[:2], "2Då’Œ3Dæ—¶é—´/å…³èŠ‚ç»´åº¦ä¸ä¸€è‡´"
    
    print("âœ… æ•°æ®å½¢çŠ¶æ£€æŸ¥é€šè¿‡")

def setup_training_environment():
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    # æ£€æŸ¥GPU
    if not torch.cuda.is_available():
        print("âŒ æ²¡æœ‰å¯ç”¨çš„GPUï¼Œé€€å‡º")
        sys.exit(1)
    
    device = torch.device("cuda")
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    print(f"ğŸ–¥ï¸ GPU: {gpu_name}")
    print(f"ğŸ’¾ æ˜¾å­˜: {gpu_memory:.1f} GB")
    
    # è®¾ç½®cuDNNåŸºå‡†
    torch.backends.cudnn.benchmark = True
    
    return device

def create_data_generators(train_3d, train_2d, val_3d, val_2d, 
                          batch_size, seq_len, kps_left, kps_right):
    """åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨ - ä½¿ç”¨å…¼å®¹çš„å‚æ•°"""
    
    try:
        # å°è¯•ä½¿ç”¨æ ‡å‡†å‚æ•°
        train_gen = ChunkedGenerator(
            batch_size, 
            None,  # cameras
            train_3d, 
            train_2d,
            chunk_length=seq_len,
            shuffle=True,
            augment=True,  # åªè®¾ç½®augment=Trueï¼Œè®©å†…éƒ¨ä½¿ç”¨é»˜è®¤å‚æ•°
            kps_left=kps_left,
            kps_right=kps_right,
            joints_left=kps_left,
            joints_right=kps_right
        )
        
        val_gen = ChunkedGenerator(
            batch_size,
            None,
            val_3d,
            val_2d,
            chunk_length=seq_len,
            shuffle=False,
            augment=False,
            kps_left=kps_left,
            kps_right=kps_right,
            joints_left=kps_left,
            joints_right=kps_right
        )
        
        print("âœ… æ•°æ®ç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ")
        return train_gen, val_gen
        
    except TypeError as e:
        print(f"âš ï¸ æ ‡å‡†å‚æ•°å¤±è´¥: {e}")
        print("å°è¯•ä½¿ç”¨æœ€ç®€å‚æ•°...")
        
        # ä½¿ç”¨æœ€ç®€å‚æ•°
        train_gen = ChunkedGenerator(
            batch_size, 
            None, 
            train_3d, 
            train_2d,
            chunk_length=seq_len,
            shuffle=True
        )
        
        val_gen = ChunkedGenerator(
            batch_size,
            None,
            val_3d,
            val_2d,
            chunk_length=seq_len,
            shuffle=False
        )
        
        print("âœ… æœ€ç®€å‚æ•°æ•°æ®ç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ")
        return train_gen, val_gen

# ========== ä¸»è®­ç»ƒå‡½æ•° ==========

def train_lightweight():
    """ä¸»è®­ç»ƒå‡½æ•° - ä¸“ä¸º8GBæ˜¾å­˜ä¼˜åŒ–"""
    
    # è§£æå‚æ•°
    args = parse_args()
    
    # ========== è¶…å‚æ•°é…ç½® ==========
    SEQ_LEN = 16          # åºåˆ—é•¿åº¦ (å¿…é¡»å°!)
    BATCH_SIZE = 8        # batchå¤§å°
    GRAD_ACCUM_STEPS = 4  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (ç­‰æ•ˆbatch_size=32)
    LR = 3e-4            # å­¦ä¹ ç‡
    WARMUP_EPOCHS = 5     # é¢„çƒ­è½®æ•°
    MAX_EPOCHS = 100      # æœ€å¤§è½®æ•°
    
    # æ¨¡å‹å‚æ•°
    EMBED_DIM = 96        # åµŒå…¥ç»´åº¦
    DEPTH = 2             # Transformerå±‚æ•°
    HEADS = 4             # æ³¨æ„åŠ›å¤´æ•°
    
    print("=" * 70)
    print("ğŸš€ åŠ¨ç‰©3Då§¿æ€ä¼°è®¡ - è½»é‡ç‰ˆè®­ç»ƒ")
    print("=" * 70)
    print(f"ğŸ“‹ é…ç½®:")
    print(f"  åºåˆ—é•¿åº¦: {SEQ_LEN}")
    print(f"  Batchå¤§å°: {BATCH_SIZE} (ç´¯ç§¯{GRAD_ACCUM_STEPS}æ­¥)")
    print(f"  å­¦ä¹ ç‡: {LR}")
    print(f"  åµŒå…¥ç»´åº¦: {EMBED_DIM}")
    print(f"  Transformerå±‚: {DEPTH}")
    print(f"  æ³¨æ„åŠ›å¤´: {HEADS}")
    print("=" * 70)
    
    # è®¾ç½®ç¯å¢ƒ
    device = setup_training_environment()
    
    # ========== æ•°æ®åŠ è½½ ==========
    print("\nğŸ“‚ åŠ è½½æ•°æ®...")
    
    try:
        dataset = AnimalsDataset('npz/real_npz/data_3d_animals.npz')
        keypoints_data = np.load('npz/real_npz/data_2d_animals_gt.npz', allow_pickle=True)
        keypoints_2d = keypoints_data['positions_2d'].item()
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        sys.exit(1)
    
    # è·å–æ‰€æœ‰åŠ¨ç‰©
    all_animals = dataset.subjects()
    print(f"ğŸ¦“ åŠ¨ç‰©ç±»å‹æ•°: {len(all_animals)}")
    print(f"ğŸ¾ åŠ¨ç‰©åˆ—è¡¨: {sorted(all_animals)[:5]}..." if len(all_animals) > 5 else f"ğŸ¾ åŠ¨ç‰©åˆ—è¡¨: {sorted(all_animals)}")
    
    # è·å–å·¦å³å…³èŠ‚
    kps_left = list(dataset.skeleton().joints_left())
    kps_right = list(dataset.skeleton().joints_right())
    
    print("ğŸ”„ å‡†å¤‡å¤šè§†è§’æ•°æ®...")
    for animal in tqdm(all_animals, desc="å¤„ç†åŠ¨ç‰©", ncols=80):
        for action in dataset[animal].keys():
            if animal in keypoints_2d and action in keypoints_2d[animal]:
                num_views = len(keypoints_2d[animal][action])
                # ä¸ºæ¯ä¸ªè§†è§’åˆ›å»º3Dæ•°æ®å‰¯æœ¬
                dataset[animal][action]['positions_3d'] = [
                    dataset[animal][action]['positions'].copy() 
                    for _ in range(num_views)
                ]
    
    # ========== æ•°æ®åˆ’åˆ† ==========
    print("\nğŸ“Š æ•°æ®åˆ’åˆ†...")
    
    # æ”¶é›†æ‰€æœ‰(åŠ¨ç‰©, åŠ¨ä½œ)å¯¹
    all_data_source = []
    for animal in all_animals:
        for action in dataset[animal].keys():
            all_data_source.append((animal, action))
    
    print(f"æ€»åŠ¨ä½œåºåˆ—æ•°: {len(all_data_source)}")
    
    # å¹³è¡¡åˆ’åˆ†
    train_data_source, val_data_source = create_balanced_split(
        all_data_source, 
        train_ratio=0.8,
        seed=42
    )
    
    # ========== è·å–å¹¶æˆªæ–­æ•°æ® ==========
    train_3d, train_2d = fetch_data_with_truncation(
        train_data_source, keypoints_2d, dataset, SEQ_LEN, "è®­ç»ƒ"
    )
    
    val_3d, val_2d = fetch_data_with_truncation(
        val_data_source, keypoints_2d, dataset, SEQ_LEN, "éªŒè¯"
    )
    
    # æ£€æŸ¥æ•°æ®
    check_data_shapes(train_2d, train_3d, val_2d, val_3d)
    
    # ========== åˆ›å»ºæ¨¡å‹ ==========
    print("\nğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
    
    num_joints = train_2d[0].shape[1]
    
    model = UltraLightAnimalPoseTransformer(
        num_joints=num_joints,
        embed_dim=EMBED_DIM,
        depth=DEPTH,
        num_heads=HEADS,
        seq_len=SEQ_LEN,
        dropout=0.1
    ).to(device)
    
    # ========== ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ ==========
    optimizer = optim.AdamW(
        model.parameters(),
        lr=LR,
        weight_decay=0.01,
        betas=(0.9, 0.999)
    )
    
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=8,
        verbose=True,
        min_lr=1e-6
    )
    
    # ========== æ•°æ®ç”Ÿæˆå™¨ ==========
    print("\nğŸ”„ åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨...")
    
    train_gen, val_gen = create_data_generators(
        train_3d, train_2d, val_3d, val_2d,
        BATCH_SIZE, SEQ_LEN, kps_left, kps_right
    )
    
    # ========== è®­ç»ƒå¾ªç¯ ==========
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print("-" * 90)
    
    # è®­ç»ƒçŠ¶æ€
    best_val_loss = float('inf')
    patience_counter = 0
    max_patience = 25
    early_stop = False
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dir = args.checkpoint if hasattr(args, 'checkpoint') else 'checkpoints_light'
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # è®­ç»ƒå†å²
    train_history = []
    val_history = []
    
    for epoch in range(MAX_EPOCHS):
        # 1. å­¦ä¹ ç‡é¢„çƒ­
        if epoch < WARMUP_EPOCHS:
            warmup_lr = LR * (epoch + 1) / WARMUP_EPOCHS
            for param_group in optimizer.param_groups:
                param_group['lr'] = warmup_lr
        
        # 2. è®­ç»ƒé˜¶æ®µ
        model.train()
        epoch_train_loss = 0.0
        epoch_bone_loss = 0.0
        num_batches = 0
        accum_steps = 0
        
        optimizer.zero_grad()
        
        # ä½¿ç”¨tqdmè¿›åº¦æ¡
        pbar = tqdm(train_gen.next_epoch(), 
                   desc=f"Epoch {epoch+1:03d} è®­ç»ƒ",
                   total=len(train_gen.pairs) // BATCH_SIZE + 1,
                   ncols=80)
        
        for batch_idx, (_, batch_3d, batch_2d) in enumerate(pbar):
            # è½¬æ¢ä¸ºTensor
            batch_2d_tensor = torch.from_numpy(batch_2d.astype('float32')).to(device)
            batch_3d_tensor = torch.from_numpy(batch_3d.astype('float32')).to(device)
            
            # Root-relative
            batch_3d_tensor = batch_3d_tensor - batch_3d_tensor[:, :, 0:1, :]
            
            # å‰å‘ä¼ æ’­
            pred_3d = model(batch_2d_tensor)
            
            # è®¡ç®—æŸå¤±
            loss_mpjpe = mpjpe(pred_3d, batch_3d_tensor)
            loss_bone = bone_length_loss(pred_3d, batch_3d_tensor)
            total_loss = (loss_mpjpe + 0.1 * loss_bone) / GRAD_ACCUM_STEPS
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            
            # ç´¯ç§¯æŸå¤±
            epoch_train_loss += loss_mpjpe.item() * GRAD_ACCUM_STEPS
            epoch_bone_loss += loss_bone.item() * GRAD_ACCUM_STEPS
            accum_steps += 1
            
            # æ¢¯åº¦ç´¯ç§¯
            if accum_steps % GRAD_ACCUM_STEPS == 0:
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                # æ›´æ–°å‚æ•°
                optimizer.step()
                optimizer.zero_grad()
                
                num_batches += 1
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'loss': f"{loss_mpjpe.item()*1000:.1f}mm",
                    'bone': f"{loss_bone.item()*1000:.1f}mm"
                })
        
        # å¤„ç†å‰©ä½™çš„æ¢¯åº¦
        if accum_steps % GRAD_ACCUM_STEPS != 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            optimizer.zero_grad()
            num_batches += 1
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_train_loss = epoch_train_loss / accum_steps if accum_steps > 0 else 0
        avg_bone_loss = epoch_bone_loss / accum_steps if accum_steps > 0 else 0
        train_history.append(avg_train_loss)
        
        # 3. éªŒè¯é˜¶æ®µ
        model.eval()
        epoch_val_loss = 0.0
        val_batches = 0
        
        with torch.no_grad():
            for _, batch_3d, batch_2d in tqdm(val_gen.next_epoch(),
                                           desc=f"Epoch {epoch+1:03d} éªŒè¯",
                                           total=len(val_gen.pairs) // BATCH_SIZE + 1,
                                           ncols=80):
                # è½¬æ¢ä¸ºTensor
                batch_2d_tensor = torch.from_numpy(batch_2d.astype('float32')).to(device)
                batch_3d_tensor = torch.from_numpy(batch_3d.astype('float32')).to(device)
                
                # Root-relative
                batch_3d_tensor = batch_3d_tensor - batch_3d_tensor[:, :, 0:1, :]
                
                # å‰å‘ä¼ æ’­
                pred_3d = model(batch_2d_tensor)
                
                # è®¡ç®—æŸå¤±
                loss_mpjpe = mpjpe(pred_3d, batch_3d_tensor)
                epoch_val_loss += loss_mpjpe.item()
                val_batches += 1
        
        avg_val_loss = epoch_val_loss / val_batches if val_batches > 0 else float('inf')
        val_history.append(avg_val_loss)
        
        # 4. å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(avg_val_loss)
        
        # 5. ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            
            # ä¿å­˜å®Œæ•´æ¨¡å‹
            model_path = os.path.join(checkpoint_dir, 'best_model.pt')
            torch.save(model.state_dict(), model_path)
            
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ | éªŒè¯æŸå¤±: {avg_val_loss * 1000:.2f}mm")
        else:
            patience_counter += 1
        
        # 6. æ—©åœæ£€æŸ¥
        if patience_counter >= max_patience:
            early_stop = True
            print(f"ğŸ›‘ æ—©åœè§¦å‘ | è¿ç»­ {max_patience} ä¸ªepochéªŒè¯æŸå¤±æœªæ”¹å–„")
        
        # 7. æ‰“å°æ—¥å¿—
        current_lr = optimizer.param_groups[0]['lr']
        print(f"\nEpoch {epoch+1:03d} | "
              f"Train: {avg_train_loss * 1000:6.1f}mm | "
              f"Val: {avg_val_loss * 1000:6.1f}mm | "
              f"Bone: {avg_bone_loss * 1000:6.1f}mm | "
              f"LR: {current_lr:.2e} | "
              f"Patience: {patience_counter:2d}/{max_patience}")
        
        print("-" * 90)
        
        # 8. æ£€æŸ¥æ—©åœ
        if early_stop:
            print(f"\nğŸ¯ è®­ç»ƒå®Œæˆ!")
            print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss * 1000:.2f}mm")
            break
    
    # è®­ç»ƒå®Œæˆ
    if not early_stop:
        print(f"\nğŸ¯ è¾¾åˆ°æœ€å¤§è½®æ•° {MAX_EPOCHS}")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss * 1000:.2f}mm")
    
    print("\n" + "=" * 70)
    print("è®­ç»ƒå®Œæˆ!")
    print("=" * 70)
    
    # æ‰“å°æ€»ç»“
    print(f"\nğŸ“ˆ è®­ç»ƒæ€»ç»“:")
    print(f"  æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss * 1000:.2f}mm")
    print(f"  è®­ç»ƒè½®æ•°: {len(train_history)}")
    print(f"  æ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {checkpoint_dir}")
    
    return best_val_loss


def main():
    """ä¸»å‡½æ•°"""
    try:
        best_loss = train_lightweight()
        print(f"\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ! æœ€ä½³æŸå¤±: {best_loss * 1000:.2f}mm")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()