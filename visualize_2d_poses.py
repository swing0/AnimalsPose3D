# visualize_2d_poses_accurate.py
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
from common.keypoint_mapper import KeypointMapper


class PoseVisualizer:
    def __init__(self):
        self.mapper = KeypointMapper()

        # ä½¿ç”¨AP10Kæ£€æµ‹å™¨ä¸­çš„é¢œè‰²å’Œéª¨éª¼å®šä¹‰
        self.keypoint_colors = {
            'L_Eye': [0, 255, 0],  # ç»¿è‰²
            'R_Eye': [255, 128, 0],  # æ©™è‰²
            'Nose': [51, 153, 255],  # è“è‰²
            'Neck': [51, 153, 255],  # è“è‰²
            'Root of tail': [51, 153, 255],  # è“è‰²
            'L_Shoulder': [51, 153, 255],  # è“è‰²
            'L_Elbow': [51, 153, 255],  # è“è‰²
            'L_F_Paw': [0, 255, 0],  # ç»¿è‰²
            'R_Shoulder': [0, 255, 0],  # ç»¿è‰²
            'R_Elbow': [255, 128, 0],  # æ©™è‰²
            'R_F_Paw': [0, 255, 0],  # ç»¿è‰²
            'L_Hip': [255, 128, 0],  # æ©™è‰²
            'L_Knee': [255, 128, 0],  # æ©™è‰²
            'L_B_Paw': [0, 255, 0],  # ç»¿è‰²
            'R_Hip': [0, 255, 0],  # ç»¿è‰²
            'R_Knee': [0, 255, 0],  # ç»¿è‰²
            'R_B_Paw': [0, 255, 0]  # ç»¿è‰²
        }

        # éª¨éª¼è¿æ¥å®šä¹‰ï¼ˆåŸºäºAP10Kæ£€æµ‹å™¨ï¼‰
        self.skeleton_connections = [
            ('L_Eye', 'R_Eye'),  # 0: çœ¼ç›è¿æ¥
            ('L_Eye', 'Nose'),  # 1: å·¦çœ¼åˆ°é¼»å­
            ('R_Eye', 'Nose'),  # 2: å³çœ¼åˆ°é¼»å­
            ('Nose', 'Neck'),  # 3: é¼»å­åˆ°é¢ˆéƒ¨
            ('Neck', 'Root of tail'),  # 4: é¢ˆéƒ¨åˆ°å°¾å·´æ ¹
            ('Neck', 'L_Shoulder'),  # 5: é¢ˆéƒ¨åˆ°å·¦è‚©
            ('L_Shoulder', 'L_Elbow'),  # 6: å·¦è‚©åˆ°å·¦è‚˜
            ('L_Elbow', 'L_F_Paw'),  # 7: å·¦è‚˜åˆ°å·¦å‰çˆª
            ('Neck', 'R_Shoulder'),  # 8: é¢ˆéƒ¨åˆ°å³è‚©
            ('R_Shoulder', 'R_Elbow'),  # 9: å³è‚©åˆ°å³è‚˜
            ('R_Elbow', 'R_F_Paw'),  # 10: å³è‚˜åˆ°å³å‰çˆª
            ('Root of tail', 'L_Hip'),  # 11: å°¾å·´æ ¹åˆ°å·¦é«‹
            ('L_Hip', 'L_Knee'),  # 12: å·¦é«‹åˆ°å·¦è†
            ('L_Knee', 'L_B_Paw'),  # 13: å·¦è†åˆ°å·¦åçˆª
            ('Root of tail', 'R_Hip'),  # 14: å°¾å·´æ ¹åˆ°å³é«‹
            ('R_Hip', 'R_Knee'),  # 15: å³é«‹åˆ°å³è†
            ('R_Knee', 'R_B_Paw')  # 16: å³è†åˆ°å³åçˆª
        ]

        # éª¨éª¼é¢œè‰²ï¼ˆåŸºäºAP10Kæ£€æµ‹å™¨ï¼‰
        self.skeleton_colors = [
            [0, 0, 255],  # 0: è“è‰² - çœ¼ç›è¿æ¥
            [0, 0, 255],  # 1: è“è‰² - å·¦çœ¼åˆ°é¼»å­
            [0, 0, 255],  # 2: è“è‰² - å³çœ¼åˆ°é¼»å­
            [0, 255, 0],  # 3: ç»¿è‰² - é¼»å­åˆ°é¢ˆéƒ¨
            [0, 255, 0],  # 4: ç»¿è‰² - é¢ˆéƒ¨åˆ°å°¾å·´æ ¹
            [0, 255, 255],  # 5: é’è‰² - é¢ˆéƒ¨åˆ°å·¦è‚©
            [0, 255, 255],  # 6: é’è‰² - å·¦è‚©åˆ°å·¦è‚˜
            [0, 255, 255],  # 7: é’è‰² - å·¦è‚˜åˆ°å·¦å‰çˆª
            [6, 156, 250],  # 8: äº®è“è‰² - é¢ˆéƒ¨åˆ°å³è‚©
            [6, 156, 250],  # 9: äº®è“è‰² - å³è‚©åˆ°å³è‚˜
            [6, 156, 250],  # 10: äº®è“è‰² - å³è‚˜åˆ°å³å‰çˆª
            [0, 255, 255],  # 11: é’è‰² - å°¾å·´æ ¹åˆ°å·¦é«‹
            [0, 255, 255],  # 12: é’è‰² - å·¦é«‹åˆ°å·¦è†
            [0, 255, 255],  # 13: é’è‰² - å·¦è†åˆ°å·¦åçˆª
            [6, 156, 250],  # 14: äº®è“è‰² - å°¾å·´æ ¹åˆ°å³é«‹
            [6, 156, 250],  # 15: äº®è“è‰² - å³é«‹åˆ°å³è†
            [6, 156, 250]  # 16: äº®è“è‰² - å³è†åˆ°å³åçˆª
        ]

    def create_canvas(self, width=1000, height=1000, bg_color=(255, 255, 255)):
        """åˆ›å»ºç”»å¸ƒ"""
        return np.ones((height, width, 3), dtype=np.uint8) * bg_color

    def draw_pose(self, canvas, keypoints, confidence_threshold=0.0):
        """
        åœ¨ç”»å¸ƒä¸Šç»˜åˆ¶å®Œæ•´çš„å§¿æ€

        Args:
            canvas: ç”»å¸ƒå›¾åƒ
            keypoints: å…³é”®ç‚¹æ•°ç»„ (17, 2) æˆ– (17, 3)
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        # é¦–å…ˆç»˜åˆ¶éª¨éª¼è¿æ¥
        for i, (start_name, end_name) in enumerate(self.skeleton_connections):
            # è·å–å…³é”®ç‚¹ç´¢å¼•
            start_idx = self.mapper.training_keypoints_order.index(
                self.mapper.ap10k_to_training[start_name]
            )
            end_idx = self.mapper.training_keypoints_order.index(
                self.mapper.ap10k_to_training[end_name]
            )

            if start_idx < len(keypoints) and end_idx < len(keypoints):
                start_kp = keypoints[start_idx]
                end_kp = keypoints[end_idx]

                # æ£€æŸ¥ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰å…³é”®ç‚¹åˆ†æ•°ï¼‰
                start_conf = start_kp[2] if len(start_kp) == 3 else 1.0
                end_conf = end_kp[2] if len(end_kp) == 3 else 1.0

                if start_conf > confidence_threshold and end_conf > confidence_threshold:
                    start_point = (int(start_kp[0]), int(start_kp[1]))
                    end_point = (int(end_kp[0]), int(end_kp[1]))

                    # ç»˜åˆ¶éª¨éª¼
                    color = tuple(self.skeleton_colors[i])
                    cv2.line(canvas, start_point, end_point, color, 3)

        # ç„¶åç»˜åˆ¶å…³é”®ç‚¹
        for i, kp in enumerate(keypoints):
            if len(kp) >= 2:
                x, y = int(kp[0]), int(kp[1])
                confidence = kp[2] if len(kp) == 3 else 1.0

                if confidence > confidence_threshold:
                    # è·å–å…³é”®ç‚¹åç§°å’Œé¢œè‰²
                    kp_name = self.mapper.training_keypoints_order[i]
                    ap10k_name = self.mapper.training_to_ap10k[kp_name]
                    color = tuple(self.keypoint_colors[ap10k_name])

                    # ç»˜åˆ¶å…³é”®ç‚¹
                    cv2.circle(canvas, (x, y), 8, color, -1)
                    cv2.circle(canvas, (x, y), 8, (255, 255, 255), 2)

                    # æ·»åŠ å…³é”®ç‚¹æ ‡ç­¾
                    label = f"{i}:{ap10k_name}"
                    cv2.putText(canvas, label, (x + 10, y - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)

    def visualize_single_pose(self, keypoints, save_path=None, show=True):
        """å¯è§†åŒ–å•ä¸ªå§¿æ€"""
        canvas = self.create_canvas(1000, 1000)
        self.draw_pose(canvas, keypoints)

        # æ·»åŠ æ ‡é¢˜
        cv2.putText(canvas, "2D Animal Pose Visualization", (20, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

        if save_path:
            cv2.imwrite(save_path, canvas)
            print(f"âœ… å§¿æ€å›¾åƒå·²ä¿å­˜: {save_path}")

        if show:
            # è½¬æ¢ä¸ºRGBæ˜¾ç¤º
            canvas_rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)
            plt.figure(figsize=(10, 10))
            plt.imshow(canvas_rgb)
            plt.axis('off')
            plt.title("2D Animal Pose")
            plt.tight_layout()
            plt.show()

        return canvas


def visualize_2d_poses_accurate(npz_path, output_dir="visualization/2d_poses_accurate"):
    """
    å‡†ç¡®å¯è§†åŒ–2Då§¿æ€æ•°æ®ï¼Œä½¿ç”¨æ­£ç¡®çš„å…³é”®ç‚¹æ˜ å°„

    Args:
        npz_path: 2Då§¿æ€NPZæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    os.makedirs(output_dir, exist_ok=True)

    print(f"ğŸ“ åŠ è½½2Då§¿æ€æ•°æ®: {npz_path}")

    # åŠ è½½æ•°æ®
    data = np.load(npz_path, allow_pickle=True)

    if 'positions_2d' not in data.files:
        print("âŒ æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° 'positions_2d' æ•°æ®")
        return

    positions_2d = data['positions_2d'].item()
    metadata = data['metadata'].item() if 'metadata' in data.files else {}

    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = PoseVisualizer()

    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  ä¸»ä½“æ•°é‡: {len(positions_2d)}")

    # ä¸ºæ¯ä¸ªä¸»ä½“å’ŒåŠ¨ä½œåˆ›å»ºå¯è§†åŒ–
    for subject, actions in positions_2d.items():
        print(f"\nğŸ¨ å¯è§†åŒ–ä¸»ä½“: {subject}")

        for action, camera_views in actions.items():
            print(f"  åŠ¨ä½œ: {action}")

            for cam_idx, poses in enumerate(camera_views):
                print(f"    ç›¸æœº {cam_idx}: {poses.shape} å¸§")

                # åˆ›å»ºè¾“å‡ºå­ç›®å½•
                action_dir = os.path.join(output_dir, f"{subject}_{action}_cam{cam_idx}")
                os.makedirs(action_dir, exist_ok=True)

                total_frames = len(poses)

                # é€‰æ‹©å…³é”®å¸§è¿›è¡Œå¯è§†åŒ–
                sample_frames = min(10, total_frames)  # æœ€å¤šå¯è§†åŒ–10å¸§
                step = max(1, total_frames // sample_frames)

                print(f"      é‡‡æ · {sample_frames} å¸§è¿›è¡Œå¯è§†åŒ–...")

                for frame_idx in range(0, total_frames, step):
                    if frame_idx >= total_frames:
                        break

                    # è·å–å½“å‰å¸§çš„å…³é”®ç‚¹
                    keypoints = poses[frame_idx]

                    # å¯è§†åŒ–å•ä¸ªå§¿æ€
                    output_path = os.path.join(action_dir, f"frame_{frame_idx:06d}.png")
                    canvas = visualizer.visualize_single_pose(
                        keypoints,
                        save_path=output_path,
                        show=False  # ä¸æ˜¾ç¤ºï¼Œåªä¿å­˜
                    )

                    # åœ¨å›¾åƒä¸Šæ·»åŠ å¸§ä¿¡æ¯
                    cv2.putText(canvas, f"Frame: {frame_idx}/{total_frames}",
                                (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                    cv2.putText(canvas, f"Camera: {cam_idx}",
                                (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

                    # é‡æ–°ä¿å­˜å¸¦ä¿¡æ¯çš„å›¾åƒ
                    cv2.imwrite(output_path, canvas)

                print(f"    âœ… ç›¸æœº {cam_idx} å¯è§†åŒ–å®Œæˆ: {action_dir}")

                # åˆ›å»ºç¬¬ä¸€å¸§çš„é¢„è§ˆ
                if len(poses) > 0:
                    preview_path = os.path.join(output_dir, f"preview_{subject}_{action}_cam{cam_idx}.png")
                    visualizer.visualize_single_pose(
                        poses[0],
                        save_path=preview_path,
                        show=False
                    )

    # åˆ›å»ºæ±‡æ€»ä¿¡æ¯
    create_summary_report(positions_2d, output_dir)

    print(f"\nğŸ‰ æ‰€æœ‰å¯è§†åŒ–å®Œæˆ! è¾“å‡ºç›®å½•: {output_dir}")


def create_summary_report(positions_2d, output_dir):
    """åˆ›å»ºæ±‡æ€»æŠ¥å‘Š"""
    summary_path = os.path.join(output_dir, "visualization_summary.txt")

    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("2Då§¿æ€å¯è§†åŒ–æ±‡æ€»æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")

        f.write("å…³é”®ç‚¹æ˜ å°„ä¿¡æ¯:\n")
        f.write("-" * 40 + "\n")

        mapper = KeypointMapper()
        for ap10k_name, training_name in mapper.ap10k_to_training.items():
            ap10k_idx = mapper.ap10k_mapping[ap10k_name]
            training_idx = mapper.training_keypoints_order.index(training_name)
            f.write(f"AP10K: {ap10k_name:<15} ({ap10k_idx:2d}) -> ")
            f.write(f"è®­ç»ƒ: {training_name:<15} ({training_idx:2d})\n")

        f.write("\næ•°æ®ç»Ÿè®¡:\n")
        f.write("-" * 40 + "\n")
        f.write(f"æ€»ä¸»ä½“æ•°: {len(positions_2d)}\n")

        for subject, actions in positions_2d.items():
            f.write(f"\nä¸»ä½“: {subject}\n")
            for action, camera_views in actions.items():
                f.write(f"  åŠ¨ä½œ: {action}\n")
                for cam_idx, poses in enumerate(camera_views):
                    f.write(f"    ç›¸æœº {cam_idx}: {poses.shape} å¸§\n")

    print(f"ğŸ“ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")


def interactive_pose_explorer(npz_path):
    """
    äº¤äº’å¼å§¿æ€æµè§ˆå™¨
    """
    data = np.load(npz_path, allow_pickle=True)
    positions_2d = data['positions_2d'].item()

    visualizer = PoseVisualizer()

    # é€‰æ‹©ç¬¬ä¸€ä¸ªä¸»ä½“å’ŒåŠ¨ä½œ
    subject = list(positions_2d.keys())[0]
    action = list(positions_2d[subject].keys())[0]
    camera_views = positions_2d[subject][action]

    print(f"ğŸ” äº¤äº’å¼å§¿æ€æµè§ˆå™¨: {subject}/{action}")
    print("æ§åˆ¶å‘½ä»¤:")
    print("  'n' - ä¸‹ä¸€å¸§")
    print("  'p' - ä¸Šä¸€å¸§")
    print("  'c' - åˆ‡æ¢ç›¸æœº")
    print("  'q' - é€€å‡º")

    cam_idx = 0
    frame_idx = 0
    poses = camera_views[cam_idx]

    while True:
        canvas = visualizer.create_canvas()
        keypoints = poses[frame_idx]
        visualizer.draw_pose(canvas, keypoints)

        # æ˜¾ç¤ºä¿¡æ¯
        info_text = [
            f"Subject: {subject}",
            f"Action: {action}",
            f"Camera: {cam_idx}/{len(camera_views) - 1}",
            f"Frame: {frame_idx}/{len(poses) - 1}",
            "Press 'n': next, 'p': previous, 'c': camera, 'q': quit"
        ]

        for i, text in enumerate(info_text):
            cv2.putText(canvas, text, (20, 30 + i * 25),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

        cv2.imshow("2D Pose Explorer", canvas)

        key = cv2.waitKey(0) & 0xFF
        if key == ord('n'):  # ä¸‹ä¸€å¸§
            frame_idx = min(frame_idx + 1, len(poses) - 1)
        elif key == ord('p'):  # ä¸Šä¸€å¸§
            frame_idx = max(frame_idx - 1, 0)
        elif key == ord('c'):  # åˆ‡æ¢ç›¸æœº
            cam_idx = (cam_idx + 1) % len(camera_views)
            poses = camera_views[cam_idx]
            frame_idx = 0
        elif key == ord('q'):  # é€€å‡º
            break

    cv2.destroyAllWindows()


if __name__ == "__main__":
    NPZ_PATH = "npz/real_npz/data_2d_animals_gt.npz"

    if os.path.exists(NPZ_PATH):
        print("ğŸš€ å¼€å§‹å‡†ç¡®çš„2Då§¿æ€å¯è§†åŒ–...")

        # æ˜¾ç¤ºå…³é”®ç‚¹æ˜ å°„ä¿¡æ¯
        mapper = KeypointMapper()
        mapper.print_mapping_info()

        # æ–¹æ³•1: ç”Ÿæˆé™æ€å›¾åƒå¯è§†åŒ–
        visualize_2d_poses_accurate(NPZ_PATH)

        # æ–¹æ³•2: äº¤äº’å¼æµè§ˆå™¨ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨ï¼‰
        # interactive_pose_explorer(NPZ_PATH)

        print("\nğŸŠ å¯è§†åŒ–ä»»åŠ¡å®Œæˆ!")
    else:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {NPZ_PATH}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ 02_prepare_data_animals.py ç”Ÿæˆ2Dæ•°æ®")